import json
from openai import OpenAI
from datetime import datetime

# --- 1. Definici√≥n de Herramientas (Arsenal) ---
# Usamos un esquema JSON para que el modelo entienda qu√© datos necesitamos exactamente.
tools_schema = [
    {
        "type": "function",
        "function": {
            "name": "crear_cotizacion",
            "description": "Genera una cotizaci√≥n formal para un cliente de Vertex Coders",
            "parameters": {
                "type": "object",
                "properties": {
                    "cliente": {"type": "string", "description": "Nombre del cliente"},
                    "servicios": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Lista de servicios contratados"
                    },
                    "precio_total": {"type": "number", "description": "Total en USD"}
                },
                "required": ["cliente", "servicios", "precio_total"]
            }
        }
    }
]

# --- 2. L√≥gica de Ejecuci√≥n (Blindaje T√©cnico) ---
def ejecutar_herramienta(nombre_funcion, argumentos):
    """
    Ejecuta la acci√≥n solicitada por la IA con validaci√≥n de errores.
    """
    try:
        if nombre_funcion == "crear_cotizacion":
            # Validaci√≥n de argumentos: nos aseguramos de que los datos existan
            cliente = argumentos.get('cliente')
            total = argumentos.get('precio_total')
            
            if not cliente or total is None:
                raise ValueError("Argumentos incompletos para procesar la cotizaci√≥n.")

            # Simulamos la integraci√≥n con Vertex Systems
            return json.dumps({
                "status": "success", 
                "message": f"Cotizaci√≥n de ${total} enviada a {cliente} v√≠a Vertex Systems"
            })
            
        return json.dumps({"status": "error", "message": "Herramienta no encontrada"})

    except Exception as e:
        return json.dumps({"status": "error", "message": f"Error en ejecuci√≥n: {str(e)}"})

# --- 3. El Motor de Orquestaci√≥n ---
if __name__ == "__main__":
    # Conexi√≥n soberana a LM Studio
    client = OpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")
    
    PROMPT_SISTEMA = "Eres el agente comercial de Vertex Coders. Usa la funci√≥n crear_cotizacion para gestionar pedidos."

    tarea_usuario = "Hola, soy Denis de Miami. Necesito una cotizaci√≥n para un desarrollo Full Stack y una auditor√≠a de Nemesis IA por 2500 d√≥lares."
    
    print(f"üì• Solicitud: {tarea_usuario}\n")

    try:
        response = client.chat.completions.create(
            model="qwen2-7b-instruct",
            messages=[
                {"role": "system", "content": PROMPT_SISTEMA},
                {"role": "user", "content": tarea_usuario}
            ],
            tools=tools_schema,
            tool_choice="auto"
        )

        respuesta_llm = response.choices[0].message

        # Verificamos si el LLM activ√≥ una herramienta
        if respuesta_llm.tool_calls:
            for tool_call in respuesta_llm.tool_calls:
                nombre = tool_call.function.name
                
                # Validaci√≥n del JSON de argumentos
                try:
                    argumentos = json.loads(tool_call.function.arguments)
                    print(f"üõ†Ô∏è  Agente solicita: {nombre}")
                    print(f"üì¶ Argumentos: {argumentos}")
                    
                    resultado = ejecutar_herramienta(nombre, argumentos)
                    print(f"üîç Resultado: {resultado}")
                except json.JSONDecodeError:
                    print("üö® Error: La IA envi√≥ un formato de argumentos inv√°lido.")
        else:
            print(f"ü§ñ Respuesta directa: {respuesta_llm.content}")

    except Exception as e:
        print(f"‚ùå Error de conexi√≥n o modelo: {e}")